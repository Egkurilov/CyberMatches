#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –º–∞—Ç—á–µ–π
"""

import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

URL = "https://liquipedia.net/dota2/Liquipedia:Matches"
HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15"
    ),
    "Accept-Language": "en-US,en;q=0.9,ru;q=0.8",
}

def test_parser():
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–µ—Ä –º–∞—Ç—á–µ–π...")
    
    try:
        html = requests.get(URL, headers=HEADERS, timeout=15).text
        soup = BeautifulSoup(html, 'lxml')
        
        print(f"‚úÖ HTML –∑–∞–≥—Ä—É–∂–µ–Ω, —Ä–∞–∑–º–µ—Ä: {len(html)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ò—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã —Å –º–∞—Ç—á–∞–º–∏
        match_containers = soup.find_all('div', class_=['new-match-style', 'match-info'])
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –Ω–æ–≤–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞: {len(match_containers)}")
        
        if not match_containers:
            # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
            match_containers = soup.find_all('div', class_=lambda x: x and 'match' in x.lower() and not any(word in str(x).lower() for word in ['menu', 'nav', 'header', 'footer', 'sidebar', 'rematch']))
            print(f"üìä –ù–∞–π–¥–µ–Ω–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ —Å match –≤ –∫–ª–∞—Å—Å–µ (—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ): {len(match_containers)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        for i, container in enumerate(match_containers[:3]):
            print(f"\n=== –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä {i+1} ===")
            
            # –ò—â–µ–º –≤—Ä–µ–º—è
            time_elem = container.find(['span', 'div'], class_=lambda x: x and 'timer-object' in str(x))
            if not time_elem:
                time_elem = container.find(['span', 'div'], class_=lambda x: x and any(word in str(x).lower() for word in ['time', 'date', 'countdown']))
            
            if time_elem:
                print(f"‚è∞ –í—Ä–µ–º—è: {time_elem.get_text(strip=True)}")
            else:
                print("‚è∞ –í—Ä–µ–º—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
            # –ò—â–µ–º –∫–æ–º–∞–Ω–¥—ã
            team_elems = container.find_all(['span', 'div'], class_=lambda x: x and 'team' in str(x).lower())
            teams = []
            for team_elem in team_elems:
                team_text = team_elem.get_text(strip=True)
                if team_text and team_text not in teams and len(team_text) > 1:
                    teams.append(team_text)
            
            print(f"üë• –ö–æ–º–∞–Ω–¥—ã: {teams}")
            
            # –ò—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –º–∞—Ç—á
            match_link = container.find('a', href=lambda x: x and '/dota2/Match:' in x)
            if match_link:
                match_url = urljoin('https://liquipedia.net', match_link.get('href'))
                print(f"üîó URL –º–∞—Ç—á–∞: {match_url}")
            else:
                print("üîó URL –º–∞—Ç—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω")
            
            # –ò—â–µ–º —Å—á–µ—Ç
            score_elem = container.find(['span', 'div'], class_=lambda x: x and 'score' in str(x).lower())
            if score_elem:
                score_text = score_elem.get_text(strip=True)
                print(f"üéØ –°—á–µ—Ç: {score_text}")
            else:
                print("üéØ –°—á–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
            
            # –ò—â–µ–º —Ç—É—Ä–Ω–∏—Ä
            tournament_elem = container.find(['span', 'div'], class_=lambda x: x and any(word in str(x).lower() for word in ['tournament', 'league', 'event']))
            if tournament_elem:
                tournament = tournament_elem.get_text(strip=True)
                print(f"üèÜ –¢—É—Ä–Ω–∏—Ä: {tournament}")
            else:
                print("üèÜ –¢—É—Ä–Ω–∏—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        print(f"\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ {len(match_containers)} –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ —Å –º–∞—Ç—á–∞–º–∏.")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ –º–∞—Ç—á–∏
        match_links = soup.find_all('a', href=lambda x: x and '/dota2/Match:' in x)
        print(f"üîó –í—Å–µ–≥–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ –º–∞—Ç—á–∏: {len(match_links)}")
        
        if match_links:
            print("–ü–µ—Ä–≤—ã–µ 5 —Å—Å—ã–ª–æ–∫:")
            for i, link in enumerate(match_links[:5]):
                print(f"  {i+1}. {link.get('href')}")
        
        return len(match_containers) > 0
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        return False

if __name__ == "__main__":
    success = test_parser()
    if success:
        print("\nüéâ –ü–∞—Ä—Å–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –Ω–∞—Ö–æ–¥–∏—Ç –º–∞—Ç—á–∏!")
    else:
        print("\n‚ö†Ô∏è –ü–∞—Ä—Å–µ—Ä –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç –º–∞—Ç—á–∏, –Ω—É–∂–Ω–∞ –¥–æ—Ä–∞–±–æ—Ç–∫–∞.")
